import polka from 'polka';
import send from '@polka/send-type';
import datastore from 'nedb-promise';
import { createReadStream } from 'fs';

import rawMigrographData from '../data/data';

const db = datastore({ filename: 'local-db', autoload: true });

const startup = async () => {
	// Generate 20 times the original data to simulate a larger dataset
	const numDocs = await db.count({});
	const datasetSize = rawMigrographData.length;
	const multiple = 20;
	console.log(`Found ${numDocs} existing documents`);
	if (numDocs !== datasetSize * multiple) {
		const numRemoved = await db.remove({}, { multi: true });
		console.log(`Removed ${numRemoved} documents`);
		const now = new Date();
		const docs = [];
		for (let i = 0; i < (datasetSize * multiple); i++) {
			const m = Object.assign({}, rawMigrographData[i % datasetSize]);
			m.uid = i + 1;
			m.createdAt = now;
			// console.log(m);
			docs.push(m);
		}
		await db.insert(docs);
	}
}

// Run every time the server starts
(async () => {
	startup();
})();

const api = polka();

// Log incoming requests
const logger = (req, res, next) => {
  console.log(`${new Date().toLocaleTimeString()}: ${req.method} -> ${req.url}`);
  next();
};

api.use(logger);

// Return data based on query parameters entered
api.get('/query', async (req, res) => {
	// query params:
	// sortBy (text - sort by a particular column)
	// desc (boolean - true if descending order)
	// skip (number)
	// limit (number)
	const skip = req.query.skip || null;
	const limit = req.query.limit || null;
	const data = await db.cfind({})
		.sort({ [req.query.sortBy || 'uid']: req.query.desc === 'true' ? -1 : 1 })
		.skip(skip)
		.exec();
	// Bug with nedb-promise skip + limit, therefore manually slice
  send(res, 200, { success: true, data: limit !== null ? data.slice(0, limit) : data });
});

// Return various averages across the micrographs in the database
api.get('/averages', async (_, res) => {
	const data = await db.find({});
	const averages = {
		motion_curvature: (data.map(d => d.motion_curvature).reduce((a, b) => (a + b)) / data.length),
		ctf_fit_to_A: (data.map(d => d.ctf_fit_to_A).reduce((a, b) => (a + b)) / data.length),
		pick_ncc_median: (data.map(d => d.pick_ncc_median).reduce((a, b) => (a + b)) / data.length),
		num_particles: (data.map(d => d.num_particles).reduce((a, b) => (a + b)) / data.length),
		pick_pow_median: (data.map(d => d.pick_pow_median).reduce((a, b) => (a + b)) / data.length),
		df_ast: (data.map(d => d.df_ast).reduce((a, b) => (a + b)) / data.length),
		motion_total_pix: (data.map(d => d.motion_total_pix).reduce((a, b) => (a + b)) / data.length),
	};
  send(res, 200, { success: true, data: averages });
});

// Return the total count of documents in the database
api.get('/count', async (_, res) => {
	const data = await db.count({});
  send(res, 200, { success: true, data });
});

// Return an image corresponding to the filename query param
api.get('/image', async (req, res) => {
	// query params:
	// filename (string - corresponds to the fname of a micrograph)
	const filename = req.query.filename;
	if (filename) {
		let file = createReadStream(`./data/${filename}.png`);
  	send(res, 206, file, { 'Content-Type': 'image/png' });
	} else {
		send(res, 400, { success: false, data: "Invalid parameters" });
	}
});

// Utility: Return all documents
api.get('/all', async (req, res) => {
	const data = await db.cfind({}).sort({ uid: 1 }).exec();
  send(res, 200, { success: true, data });
});

// Utility: Clear the database
api.get('/clear', async (_, res) => {
	const data = await db.remove({}, { multi: true });
  send(res, 200, { success: true, data });
});

// Return a random integer to populate a timeseries plot
api.get('/random', async (_, res) => {
	const data = Math.floor(Math.random() * (2000 - 100 + 1)) + 100;
  send(res, 200, { success: true, data });
});

export default api;
